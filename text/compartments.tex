\chapter[label=compartments]{Compartments and libraries}

In most conventional operating systems, you share code with shared libraries and you isolate running code with processes.
Compartments in CHERIoT are somewhere between these two abstractions.
Unlike a process, they do not own threads, which are an independent concept in CHERIoT, described more in \ref{threads}.

Communication between compartments looks a lot more like communication between shared libraries than like inter-process communication (IPC).
They can export functions to be called form other compartments and can call functions exported from other compartments.
Like a shared library, they have code and globals associated with them, but a \keyword{cross-compartment call} crosses a security boundary, in the same way that an IPC message would.

CHERIoT shared libraries are a lightweight way of reusing code without duplicating it into different compartments.
Calling a library function does not involve crossing a security boundary.
Libraries contain code and read-only data but do not have mutable globals.
It is possible for libraries to hold secrets but, unless library functions are written in very careful assembly, they should assume that any (immutable) globals in the library can leak to callers.
Each library entry point is exposed as a sentry capability (see \ref{sealing_intro}) to the callers, which means that the caller cannot directly read its code or (immutable) data.

\begin{warning}
If a library traps, the error handler for the caller compartment may see the register file for the middle of the library.
Similarly, the compiler may spill arbitrary values onto the stack or leave them in registers at the end of a library function.
As such, you should assume that anything processed in a library written in a compiled language will leak to the caller and anything written in assembly must be \textem{very} careful to avoid leaking secrets.
This is not normally a problem because most libraries just exist as an alternative to compiling the same functions into multiple compartments.
For example, the functions that implement locks on top of futexes (see \ref{futex}) are in a library to reduce overall code size, but simply copying the implementations of these functions into each caller would have no security implications.
\end{warning}
\hugo { "most libraries just exist as an alternative to compiling the same functions into multiple compartments" is a really good desciption of what libraries are for. Maybe this should be promoted out of the warning and into the main section text above it. }

\section{Compartments and libraries export functions}

In a UNIX-like system, a shared library can export any kind of symbol.
This includes functions and global variables.
In CHERIoT, compartments and libraries can export only functions as entry points.
Global variables are always private to a compartment or library, unless a pointer is explicitly passed out as a function argument or return in a cross-compartment call.
This design is intended to make it easier to reason about sharing between compartments.

If you declare a global in a header and define it in a library or a compartment, you may see linker errors if you try to use it in other compartments or libraries.
This holds even for \c{const} globals exported from libraries.
You can place a \c{static const} global in a header for a library, but that will introduce tight coupling: the value in the header may be inlined at any use site.
For very large globals, this may also increase code size significantly.

\begin{note}
As mentioned previously, (read-only) globals in a library are hidden in a software-engineering sense, but may be leaked to callers and should not be considered private in a security sense.
\end{note}

You can still use a compartment's globals to share data but you must explicitly expose them via an accessor function.
This makes CHERIoT compartments and libraries similar to Smalltalk-style objects, with public methods and private instance variables.
You can also create globals that are shared between compartments (see \ref{_sharing_globals_between_compartments}) but these are not part of any compartment.

If you expose an interface that returns a pointer to a global, you can use CHERI permissions to restrict access.
Returning a read-only pointer to a global is a common idiom for building a lightweight broadcast communication channel.
The owning compartment can write to the global and other compartments can read from via their copy of the pointer, with guarantees that only the owning compartment is making changes.

To see the differences, \ref{lst:exportcompartmentandlib} shows a header that exports two functions, one from a compartment and one from a library.

\codelisting[filename=examples/library_or_compartment/interface.h,marker=exports,label=lst:exportcompartmentandlib,caption="A header defining library and compartment exports."]{}

The exported functions both contain the implementation shown in \ref{lst:printcompartmentregisters}, which uses the debug APIs (see \ref{debug}) to print the capabilities in three registers.
This listing shows the version in the library but the code in the compartment is identical.
There are two compartments in this example, the entry compartment and the compartment that it calls.

The exported (library and compartment) functions will print the stack, code, and globals regions, respectively.
The compiler provides builtin functions to copy two of these (the program counter and stack capabilities) but the third, the globals pointer, requires some inline assembly.
The inline assembly needs to run at the start of the function because this function does not reference any globals and so the compiler will otherwise spill this register to use it as a temporary.

\codelisting[filename=examples/library_or_compartment/library.cc,marker=library_implementation,label=lst:printcompartmentregisters,caption="A simple print function to introspect compartment state."]{}

When you run this code, you should see output something like this:

\begin{console}
Entry: Stack pointer: 0x80000d30 (v:1 0x80000750-0x80000d50 l:0x600 o:0x0 p: - RWcgml -- ---)
Entry: Program counter: 0x80005f18 (v:1 0x80005ee0-0x80005fe8 l:0x108 o:0x0 p: G R-cgm- X- ---)
Entry: Globals pointer: 0x80006202 (v:1 0x80006200-0x80006204 l:0x4 o:0x0 p: G RWcgm- -- ---)
Library: Stack pointer: 0x80000d20 (v:1 0x80000750-0x80000d50 l:0x600 o:0x0 p: - RWcgml -- ---)
Library: Program counter: 0x80005d48 (v:1 0x80005d20-0x80005df8 l:0xd8 o:0x0 p: G R-cgm- X- ---)
Library: Globals pointer: 0x80006202 (v:1 0x80006200-0x80006204 l:0x4 o:0x0 p: G RWcgm- -- ---)
Compartment: Stack pointer: 0x80000cf0 (v:1 0x80000750-0x80000d10 l:0x5c0 o:0x0 p: - RWcgml -- ---)
Compartment: Program counter: 0x80005e20 (v:1 0x80005df8-0x80005ee0 l:0xe8 o:0x0 p: G R-cgm- X- ---)
Compartment: Globals pointer: 0x800061fe (v:1 0x800061fc-0x80006200 l:0x4 o:0x0 p: G RWcgm- -- ---)
\end{console}

Ignore the exact memory addresses, these may change depending on where you run the example.
First, note that the program counter capability (the capability used for instruction fetch) is different in all three cases and the bounds do not overlap.
In this particular build, the called compartment is placed in code memory immediately after the entry compartment, so the address 0x80005df8 is the boundary between the two.

Next, observe that the globals pointer is different between the entry compartment and the one that is called in the last three lines of the output.
This example includes a single \c{int} global, to make sure that these are non-zero (two compartments may have the same zero-length capabilities for globals if they have no globals).
In contrast, the library prints the same globals pointer as the caller.
As previously mentioned, a malicious library can access any globals in the caller.

Finally, look at the stack pointers.
The first thing to note is that the \textem{start} address is 0x80000750 in all cases.
This is because the stack belongs to the thread and not the compartment. 
Stacks grow downwards and the \textem{end} of the stack is the same for each.
The \textem{address} of the stack pointer is different in each because they run at different depths on the stack.
The initial value is very close to the top of the stack, then the library and compartment calls are deeper.
A compartment call needs to save more state (two callee-save registers and the old global pointer, which are preserved across normal calls) and so entry to the compartment call is slightly (48 bytes) lower.
The top of the stack is the most interesting place.
In the compartment call, the top of the stack is at address 0x80000d10, 64 bytes below its location in the entry compartment and the library.
Anything above that point is unreachable in the compartment before then.
The length shows this truncation another way.
The original had 0x600 bytes of stack but this is reduced to 0x5c0 after the cross-compartment call.

This may all be easier to understand visually.
\ref{compartmentcallregisters} shows the memory ranges that each compartment points to, in each of the three places.
\if[output=sile]{The lines marked with a 1 indicate the initial values on entry, those marked 2 indicate the values in the library call and those marked 3 show the values in the cross-compartment call.}
\else[output=sile]{The lines marked with a ⓵ indicate the initial values on entry, those marked ⓶ indicate the values in the library call and those marked ⓷ show the values in the cross-compartment call.}

\figure[label=compartmentcallregisters,src=figures/CompartmentCall.svg,alt=An illustration of the memory pointed to by each compartment in the compartment and library-call example.]{An illustration of memory pointed to by each register in the compartment-call example.}

\section{Understanding the structure of a compartment}

From a distance, a compartment is a very simple construct.
The core of a compartment is made of just two capabilities.
The program counter capability (PCC) defines (and grants access to) the range of memory covering the compartment's code and read-only globals.
This has read and execute permissions.
The capability global pointer (CGP) defines (and grants access to) the range of memory covering the compartment's mutable globals.
The full structure is more complex and is shown in \ref{compartmentstructure}.

\figure[label=compartmentstructure,src=figures/CompartmentStructure.svg,alt="The structure of a compartment.  The PCC register points a code region that contains code, read-only globals, and an import table.  The CGP register points to the read-write globals region.  An export table is not directly reachable."]{The structure of a compartment.}

\hugo{ It's not clear as it could be that PCC points to all three of the top boxes as oppose to just 'code and read-only data' in the diagram. }

\begin{note}
A future version of the ABI may move read-only globals out of the program counter capability region but this requires some ISA changes to be efficient and so will likely not happen before CHERIoT 2.0.
\end{note}

If a compartment didn't need to interact with anything else, these two regions would be sufficient.
In practice, compartments are useful only because they interact with other compartments or the outside world.
The read-only data region contains an \keyword{import table}.
This is the only region of memory that, at system start, is allowed to contain capabilities that grant access outside of the PCC and CGP region for the compartment.
The instructions for the loader to populate these are in the firmware image and are amenable to auditing.

The import table contains three kinds of capabilities.
MMIO capabilities are conceptually simple: they are just pointers that grant access to specific devices.
This mechanism allows byte-granularity access to device registers and so it's possible to provide a compartment with access to a single device register from a large device.

Import tables also contain sentry capabilities for library functions.
A shared library has its own PCC region (like a compartment) but does not have a CGP region.
Library routines are invoked by loading the sentry from the import table and jumping to it.

Finally, import tables contain sealed capabilities referring to other compartments' \keyword{export tables}.
If a compartment exports any entry points for other compartments to call, it has an export table.
This contains the PCC and CGP for the compartment and a small amount of metadata for each exported function describing:

\begin{itemize}
	\item{The location of the entry point.}
	\item{Whether interrupts are enabled or disabled when invoking this function.}
	\item{How many argument registers are used (conversely, how many are unused and should be zeroed).}
\end{itemize}

\hugo{ It may be nice to briefly mention which fields a library's tables would never have. }

This is all of the information that the switcher needs to transition from one compartment to another.

Extracting code and moving it to a new compartment adds a very small amount of memory overhead, on the order of a dozen words for a typical compartment.

\section{Adding compartments to the build system}

The build system makes adding compartments trivial.
An \command{xmake} build file (\file{xmake.lua}) uses a declarative Lua-like syntax at the top level.
This defines targets as sections.
\hugo{ nitpick }
\ref{lst:xmakeaddcompartmenttargets} shows the build system logic for the example compartments and libraries from earlier.
Defining a new target implicitly ends the definition of the previous one.
This example implicitly ends the library and entry targets, but uses \lua{target_end()} to explicitly end the compartment target.

\lualisting[filename=examples/library_or_compartment/xmake.lua,marker=compartments_and_libraries,label=lst:xmakeaddcompartmenttargets,caption="Build system code for defining compartment and library targets"]{}

Inside each target definition, you can add files, dependencies on other targets, and so on.
The \lua{"entry"} target, for example, sets itself as a non-default target.
\command{xmake} will build every default target, whether it is used or not.
Marking a target as non-default allows it to be defined, but built only if it is used.
This is useful for reusable components.
The RTOS provides build-system logic for a set of libraries, but each is built only if it is added as a dependency of something that is built.

\begin{note}
The \lua{compartment}, \lua{library}, and \lua{firmware} target markers are syntactic sugar over the \command{xmake} \lua{target} command.
The first two simply set the default rules to build as the correct kind of target.
The \lua{firmware} target definition is more complex because it also implicitly instantiates core parts of the RTOS, constructs the linker script, and so on.
If you are reading the \href[src="https://xmake.io"]{\command{xmake} documentation}, simply treat these as if they were \lua{target} definitions.
\end{note}

\hugo{
  Noticed on my second read through with the book:
  The xmake href footnote is on the wrong page in the draft book.
  The lua text isn't being rendered.
}

\begin{note}
	If your \file{xmake.lua} file contains compartment or library definitions but no firmware, then it can be reused.
	Each of the optional libraries and compartments shipped with the RTOS is defined like this, they are in a separate \file{xmake.lua} that is then included.
	As long as the components are set as non-default, they will simply be available for firmware to add as dependencies.
\end{note}

Once you have defined the rules to build each compartment and library, they need to be combined into a firmware image.
Any library or compartment that is a direct or indirect dependency of a firmware image will be built and linked into the final image.
For this example, we show both forms.
The entry compartment lists both the library and the example compartment as explicit dependencies because it calls both of them.
In the firmware definition (\ref{lst:xmakeaddcompartmentdeps}) adds the entry compartment as an explicit dependency, which then pulls in the other two.
This firmware also depends on two libraries from the core RTOS, the freestanding library, which provides the core of the C run-time environment, and the debug library which is pretty-printing the debug messages.

\lualisting[filename=examples/library_or_compartment/xmake.lua,marker=compartments_as_dependencies,label=lst:xmakeaddcompartmentdeps,caption="Build system code for adding dependencies on compartment and library targets"]{}

\section{Choosing a trust model}

There are three trust models that are commonly applied to compartments:

\begin{description}
	\item[tag=Sandbox]{ A sandbox is a compartment that is used to isolate
		untrusted code.
		This model is used to protect the rest of the system.
		Typically, a sandbox will trust values passed to it as arguments to exported functions or return values from functions that it calls in other compartments.}
		\item[tag=Safebox]{ A safebox is a compartment that holds some secret or sensitive data that must be protected from the outside.
		For example, a safebox may be used to protect a key and perform encryption or signing on behalf of callers.
		\hugo{ nit: 'and' and 'or' in close proximity. a comma would probably help readability. }
		A safebox does not trust any data provided from outside of the compartment, but callers may trust it to behave correctly.}
	\item[tag=Mutual distrust]{ Mutual distrust is the strongest model.
		A compartment in a mutual-distrust relationship protects itself from attacks from the outside by careful handling of inputs and expects other compartments to protect themselves from it in the same way.}
\end{description}

This is the start of defining a threat model for your code.
A compartment may simply be used for fault isolation, to limit the damage that a bug can do.
You may assume that an attacker will be able to compromise some compartments (for example, those directly processing network packets) and defend yourself accordingly.

In the core of the RTOS, the scheduler is written as a safebox.
It does not trust anything on the outside and assumes that everything else is trying to make it crash.
The memory allocator is also written as a safebox, assuming that everything else is trying to either make it crash or leak powerful capabilities.
For some operations, the scheduler invokes the allocator.
The scheduler trusts the allocator to enforce heap memory safety.
It does not, for example, try to check that the memory allocator is returning disjoint capabilities (it can't see every other caller of \c{heap_allocate}, and so couldn't validate this).
It is, however, written to assume that other compartments may try to maliciously call allocator APIs to cause it to crash, for example by freeing memory that the scheduler is using.
When thinking about trust, it's worth trying to articulate the properties that other code is trusted to enforce or preserve.
For example, everything in the CHERIoT system trusts the scheduler for availability.
Most things trust the allocator to enforce spatial and temporal memory safety for the heap.

\section{Implementing a safebox}

The safebox abstraction is trivial to implement in CHERIoT.
\ref{lst:guessthenumber} shows a complete implementation of a simple safebox for a guess-the-number game.
This generates a (very weak!) pseudorandom number using the cycle counter and allows callers to guess it.

\codelisting[marker=safebox,caption=A safebox for a guess-the-numbers game,label=lst:guessthenumber, filename=examples/safebox/safebox.cc]{}

This is called from the runner compartment, shown in \ref{lst:guessthenumberrunner}.
This compartment talks directly to the outside world and so is part of the attack surface.
It's quite unlikely that a compartment that simply reads individual bytes and ignores anything not in the ASCII digit range could be vulnerable but the same techniques can protect much more realistic examples.

\codelisting[marker=runner,caption=The runner compartment for the guess-the-numbers game,label=lst:guessthenumberrunner, filename=examples/safebox/runner.cc]{}

When you run this, you will see output something like the following:

\begin{console}
Runner: Guess a number between 0 and 9 (inclusive)
Safebox: Guess was 3, secret was 4
Safebox: Guess was 1, secret was 8
Safebox: Guess was 9, secret was 4
Safebox: Guess was 4, secret was 3
Safebox: Guess was 8, secret was 6
Safebox: Guess was 1, secret was 0
Safebox: Guess was 2, secret was 8
Safebox: Guess was 3, secret was 5
Safebox: Guess was 5, secret was 2
Safebox: Guess was 2, secret was 3
Safebox: Guess was 1, secret was 6
Runner: Correct!  You guessed the secret was 3
\end{console}

In this example, the extra compartmentalisation doesn't really buy us anything.
You could combine these two compartments and have similar functionality.
Perhaps more importantly, separating them adds little additional complexity to the code, yet respects the \keyword{principle of least privilege}.
The code that handles I/O does not need to know the secret and the code that knows the secret does not need to be able to read via the UART.

A safebox assumes that its caller is malicious.
A compartment may start malicious or become malicious as the result of a compromise.
Try modifying only \file{runner.cc} in this example to leak the secret without any incorrect guesses.
Hopefully, you will find it impossible.

\section{Refining trust}

It seems conceptually easy to say 'this code is trusted' and 'this code is untrusted', but that rarely tells the whole story.
At a high level, components are typically trusted (or not) with respect to three properties:

\begin{description}
	\item[tag=Confidentiality]{How does information flow out of this component?}
	\item[tag=Integrity]{What how can information be modified by this component?}
	\item[tag=Availability]{What can this component prevent from working?}
\end{description}

\begin{note}
Compartments and threads are both units of isolation in a CHERIoT system.
Threads are scheduled independently and provide a building block for availability guarantees.
Only a higher-priority thread or code running with interrupts disabled can prevent an unrelated thread from making progress.
\end{note}

The relative importance of each of these varies a lot depending on context.
For example, you often don't care at all about confidentiality for encrypted data, but you would not want the plain text form to leak and you definitely wouldn't want the encryption key to leak.
If you're building a safety-critical system, availability is often key.
Dumping twenty tonnes of molten aluminium onto the factory floor will probably kill people and cost millions of dollars, so preventing that is far more important than ensuring that no one unauthorised can inspect the state of your control network.

This kind of model helps understand where you should put compartment boundaries.
If an attacker can compromise one component, what damage can they do to these properties in other compartments and in the system as a whole?

For example, consider the simplest embedded application, which just flashes an LED in a pattern.
Where should you put compartment boundaries here?
You might put the piece that prepares the pattern in one compartment and the part that interacts directly with the LED in another.
Doing this does not add security value.
Neither compartment is exposed to an attacker and so you're just protecting against bugs.
The compartment with direct access to the device is just passing a value from a function argument to the device.
It is unlikely that there will be a bug in this code that can affect the rest of the system.
Conversely, the code that can call this can do everything that this compartment can do and so you haven't reduced the damage that a bug can cause.

Now imagine a slightly more complex device where, rather than lighting a single LED, you are driving an LED strip that takes a 24-bit colour value for each LED in the strip, encoded as a waveform down a two-wire serial line.
If you generate the wrong waveform, you'll get the wrong pattern and so there is an availability property that you can protect by moving the code that pauses and toggles a GPIO pin into a separate driver compartment.
This driver routine needs to run with interrupts disabled (context switching in the middle of programming the strip would cause it to reprogram the first part twice).
Running with interrupts disabled has availability implications on the rest of the system because nothing else can run while this is happening.
If you put the driver in a separate compartment then you are protected in both directions:

\begin{itemize}
	\item{The driver is the only thing that can touch the relevant GPIO pin and so, if the code in that driver is correct, nothing can cause the strip to be incorrectly programmed.}
	\item{The driver runs with interrupts disabled but the rest of the application runs with interrupts enabled and so you can audit the driver code to ensure that it doesn't cause problems for anything else that the microcontroller is doing.}
\end{itemize}

This then gives you something to build on if you decide, for example, that you want to be able to update the lighting patterns from the Internet.
Now you want to add a network stack to be able to fetch the new patterns and an interpreter to run them.
What does the threat model look like?

The network stack is exposed to the Internet and so is the most likely place for an attack to start.
If this needs to interact with the network hardware with interrupts disabled then you probably want to put that part in a separate network driver compartment so that an attacker can't cause the network stack to sit with interrupts disabled forever.
A lot of common attacks on network stacks will simply fail on a CHERIoT system because they depend on violating memory safety but it's possible that an attacker will find novel techniques and compromise the network stack.

You will want narrow interfaces between the network stack and the TLS stack, so that the worst that an attacker with full control over the network stack compartment can do is provide invalid packets (and an attacker can do that from the Internet anyway).
The TLS stack will decode complete messages and forward them to the interpreter compartment.
TLS packets have cryptographic integrity protection and so anything that comes through this path is probably safe, unless the TLS compartment is compromised, but putting the interpreter in a separate compartment ensures that invalid interpreter code can provide different colours to the LEDs but can't damage the LEDs and can't launch attacks over the network.

\section{Validating arguments}

If a function that is exported from a compartment takes primitive values as arguments, there's little that an attacker can do other than provide invalid values.
For things like integers, this doesn't matter, for enumerations it's important to ensure that they are valid values.

Pointers are more complicated.
There are a few things that an attacker can do with pointer arguments to invoke a crash:

\begin{itemize}
	\item{Provide a pointer without write permission for an output operand.}
	\item{Provide a pointer without read permission for an input operand.}
	\item{Provide a pointer without global permission that must be captured and held across calls.}
	\item{Provide a pointer with a length that is too small.}
	\item{Provide something that isn't a valid pointer at all.}
	\item{Provide a pointer that overlaps your stack as an output argument.}
\end{itemize}

Any of these (or similar attacks) will allow an attacker to cause your compartment to encounter a fault when it tries to use the pointer.

In general, you will want to check permissions and bounds on any pointer argument that you're passed.
The \c{CHERI::check_pointer"} function helps here.
It checks that a pointer has (at least) the bounds and permissions that you expect and that it isn't in your current stack region.
If you don't specify a size, the default is the size of the argument type.
You can use this to quickly check any pointer that's passed to you.

\functiondoc[usr="c:@N@CHERI@FT@>4#N$@N@CHERI@S@PermissionSet#Nb#Nb#Tcheck_pointer#&t0.3#i#b#"]{check_pointer}
\hugo{ There's an extra comma after the 'i.e.' in "smart pointer, i.e., any class" }

\begin{note}
Checking the pointer is not the only option.
A CHERI fault will invoke the compartment's error handler (see \ref{handling_errors}) and so it may be possible to recover.
Some compartments choose to assume that their arguments are valid and just gracefully clean up if they aren't.
\end{note}

If a pointer refers to a heap location, there is one additional attack possible.
In general, a pointer cannot be modified after it's been checked, but the memory that a pointer refers to may be freed.
When this happens, the pointer is implicitly invalidated.
In some cases, you may simply wish to disallow pointers that point to the heap.

You can check whether a pointer refers to heap memory by calling \c{heap_address_is_valid}.
If this returns true, you can prevent deallocation by using the \keyword{claim} mechanism, described in \ref{heap_claim}.

\functiondoc{heap_address_is_valid}

Alternatively, you can use the ephemeral claim mechanism (also documented in \ref{heap_claim} to ensure that a pointer is either a pointer that cannot be freed, or to ensure that it remains live until the next cross-compartment call.
These techniques are all combined in \ref{lst:safeuartchecks}, which is a simple function that prints a string to the UART, defensively.
This first uses a lock (see \ref{threads}) to ensure that only one thread will access this function at a time.
If this compartment exposed more than one function that used the UART then the lock would need to be shared between all of them.

\codelisting[marker=safe_uart,caption=Checks to ensure that a function does not crash.,label=lst:safeuartchecks, filename=examples/check_arguments/uart.cc]{}

Next, it uses \c{heap_claim_ephemeral} to prevent concurrent deallocation.
After this, it is safe to use \cxx{check_pointer} to ensure that the permissions are correct and that this pointer does not overlap the current compartment's stack (because of the default value of CheckStack).
For a C string, this checks only that a single byte is readable.
The function then gets the length explicitly and prints either the full length of the buffer, or the buffer up to a null terminator, whichever is shorter.


You can see how well this works with the attacks shown in \ref{lst:safeuartattacks}.
This tries passing a string that is not null-terminated, a string without load permission, an untagged capability, and finally a valid capability.

\codelisting[marker=attacks,caption=Attempting to attack the safe UART.,label=lst:safeuartattacks, filename=examples/check_arguments/hello.cc]{}

When you run this example, you should see output like this:

\begin{console}
No null
Non-malicious string
\end{console}

The string that misses the null terminator is written, but then there's no overflow.
The string that has the wrong permissions and the string that is not a valid capability at all are simply not printed.
Finally, the non-malicious string is printed correctly, showing that the attacker has not been able to corrupt internal state.

\section{Ensuring adequate stack space}

The stack is shared between compartments invoked on the same thread.
The callee has access to the portion of the stack that its callers have not used.
This is most important when a compartment is called by an untrusted caller.
In this case, a malicious caller may try to consume almost all of the stack before calling a victim compartment.
The victim would then trap in a place under the attacker's control.

Before entering a compartment, the switcher will check the amount of stack space against the required amount in the export table.
By default, the compiler will fill this value with the amount that is required by the function that serves as an entry point.
This is sufficient for leaf functions, but if your function calls others (and they are not inlined) then this will be insufficient.

You can specify the stack space required by an exported function by using the \c{__cheriot_minimum_stack} attribute.
This is a function attribute that takes a single argument, the number of bytes of stack space that the function requires.
Setting this attribute ensures that the switcher will not invoke the exported function unless at least the required amount of stack space is available.
The malicious caller from the previous example would see a return value if \c{-ENOTENOUGHSTACK} and your code would not be invoked.
Using this attribute requires you to know how much stack space the function will use.

CHERIoT CPUs include a feature called a stack high-water mark that tracks the amount of stack that is used so that the switcher can avoid zeroing unused portions of the stack.
The switcher provides a function, \c{stack_lowest_used_address}, that you can call to find the lowest address.
You can then use the difference between the top of the stack capability (accessed via the \c{__builtin_cheri_stack_get} built-in function) to determine how much stack space has been used in a particular invocation of a compartment entry point.

\functiondoc{stack_lowest_used_address}

\begin{note}
This helper checks the amount of stack usage \textem{of the current compartment}.
The switcher check is not intended to ensure that the invocation of the current compartment can succeed, only that failures are detectable and recoverable.
If you want to ensure that a called compartment *also* has enough stack then you will need to add its stack requirements to those of your compartment.
\end{note}

The \file{debug.hh} header includes a C++ helper class, \cxx{StackUsageCheck}.
This takes a template argument allowing it to be disabled, enabled and just log if you use more than the expected amount of stack, or enabled and trap if you use more than the expected amount of stack.
This is most commonly used with a macro like this:

\begin{cxxsnippet}
#define STACK_CHECK(expected) \ 
       StackUsageCheck<StackMode, expected, __PRETTY_FUNCTION__> stackCheck
\end{cxxsnippet}

The \cxx{StackMode} template argument is one of \cxx{StackCheckMode::Asserting}, \cxx{StackCheckMode::Logging}, or \cxx{StackCheckMode::Disabled}.
Typically, you will use it in logging mode initially, then disabled mode in production.
Use it in asserting mode when running representative tests in CI so that it fails if you have increased your stack requirements and not updated the caller.

It's important that the tests that you run in asserting mode have good coverage.
It's typically fine for this to be function-granularity coverage: with the exception of variable-length arrays, functions stack usage does not depend on control flow within the function.

\begin{caution}
It's tempting to enable the stack checks in debug builds.
This is usually a bad idea because debug builds include extra checks that increase stack usage.
Enabling the stack checks in debug builds will cause you to demand more stack space than a release build actually needs, increasing overall memory pressure.
\end{caution}

\section[label=handling_errors]{Handling errors}

Asynchronous interrupts are all routed to the scheduler to wake up the relevant threads and schedule the correct thread.
Synchronous faults are (optionally) delivered to the compartment that caused them.
These include CHERI exceptions, invalid instruction traps, and so on: anything that can be directly attributed to the current instruction.

Compartments have two opportunities to handle these, by implementing at least one of two kinds of error handlers.

\begin{description}
	\item[tag=Rich]{Rich error handlers that have access to the full state at the point the error occurred.
		These can be written in C/C++ and can do things like step over faulting instructions and resume, or provide rich diagnostic information about the interrupted context.}
	\item[tag=Stackless]{Lightweight error handlers that must be written in assembly.}
\end{description}

When a hardware exception occurs, the switcher will first look for a \keyword{rich error handler} and prepare a call frame for it.
If there is not sufficient stack space to invoke a rich error handler, or if one is not provided by the current compartment, the switcher will then look for a \keyword{stackless error handler}.

The stackless variant will be passed the stack capability as it was on entry to the compartment and the exception cause, but no other information.
Most users will not write these but will instead use one that the platform provides.

\section{Writing rich error handlers}

You can provide a rich error handler by implementing \c{compartment_error_handler} in your compartment.

\functiondoc{compartment_error_handler}

This function is passed a copy of the register file and the exception cause registers when a fault occurs.
The \c{mcause} value will be one of the standard RISC-V exception causes, or 0x1c for CHERI faults.
CHERI faults will encode the CHERI-specific fault code and the faulting register in \c{mtval}.
You can decompose this into its component parts by calling \cxx{CHERI::extract_cheri_mtval}.

\functiondoc{extract_cheri_mtval}

\begin{warning}
The error handler is called with interrupts enabled, even if interrupts were disabled in the faulting code.
Latency-critical code should never depend on the error handler for meeting its timing.
\end{warning}

If a called compartment faults and forcibly unwinds then this will be reported as a CHERI fault with no cause (zero) in \c{mtval}.
You can use this to propagate faults up to callers, to track the number of times a cross-compartment call has failed, and so on.

The spilled register file does not contain a tagged value for the program counter capability.
This is to prevent library functions that run with interrupts disabled or with access to secrets from accidentally leaking on faults.
All other registers will be preserved exactly as they are in the register file.

\begin{note}
Error handlers are somewhat similar to UNIX signal handlers, but with some important differences.
They are invoked for synchronous faults, not arbitrary event notification.
Importantly, they are required only to handle the current compartment's errors.
You cannot, for example, call \c{malloc} in a signal handler because it would deadlock (or corrupt state) if the signal arrives during a call to \c{malloc} or \c{free}.
In contrast, if a call to \c{heap_allocate} fails then that error will be handled in the allocator compartment.
Your error handler will never be invoked in the middle of a call to the allocator and so it is fine to use error handlers to release locks and free memory.
\end{note}

At the end of your error handler, you have two choices.
You can either ask the switcher to resume, installing your modified register file (rederiving the PCC from the compartment's code capability), or you can ask it to continue unwinding.

Error handling functions are used for resource cleanup.
For example, you may wish to drop locks when an error occurs, or you may wish to reset the compartment entirely.
The \c{heap_free_all} function, discussed in \ref{shared_heap} helps with the latter.

\section{Using scoped error handling}

You are unlikely to ever write a stackless error handler.
Most of the time, you will want to link the one provided by the \file{unwind_error_handler} target.
This can be adopted by adding \lua{add_deps("unwind_error_handler")} to your compartment's target in xmake.

This implementation is intended to be used with a set of macros that provide exception-like error handling.
These maintain a stack of \c{jmp_buf} structures, as defined by \c{setjmp}.
The head of the linked list is stored at the top of the region of the stack that is visible to the current compartment invocation, in a gap left by the switcher.
Each \c{CHERIOT_DURING} macro invocation pushes an entry onto a stack that allows returning and each \c{CHERIOT_END_HANDLER} macro pops the top entry.

\hugo{ Some may not be aware of jmp_buf and setjmp. Maybe saying "standard C jmp_buf structures" would let them know it's not CHERIoT specific and that they can look it up in any C reference. }

Between these two, a \c{CHERIOT_HANDLER} is the equivalent of the start of a catch block.
This defines the start of a region where code will run if an error is triggered.
You can see this in action in \ref{lst:errorhandling}.
This uses \c{__builtin_trap}, which the compiler will transform into an invalid instruction, to force a trap.
This is a placeholder for anything that might (including in nested function calls) raise an error, such as a bounds violation, a use-after-free bug, a null-pointer dereference, and so on.

\macrodoc{CHERIOT_DURING}

\codelisting[marker=error,caption=Example of using scoped error handling,label=lst:errorhandling, filename=examples/error_handling/errors.cc]{}

If you run this example with \cxx{shouldTrap} set to \cxx{false} then it will generate the following output:

\begin{console}
Error handling example: About to try something unsafe.
Error handling example: In during block
Error handling example: Finished unsafe block.
\end{console}

The code in the \c{CHERIOT_DURING} block runs, the code in the \c{CHERIOT_HANDLER} block is omitted, and control-flow resumes after \c{CHERIOT_END_HANDLER}.
In contrast, if \cxx{shouldTrap} is \cxx{true} then the trap will transition into the switcher, which will then invoke the compartment's stackless error handler, which will then transfer control into the \c{CHERIOT_HANDLER} block and you'll see output like this:

\begin{console}
Error handling example: About to try something unsafe.
Error handling example: In during block
Error handling example: Something bad happened!
Error handling example: Finished unsafe block.
\end{console}

This lets you do things like release locks or clean up per-call state in case of failure.

\section{Conventions for cross-compartment calls}

If a compartment faults and force unwinds to the caller then the return registers will be set to \c{-1}.
This makes it easy to use the UNIX convention of returning negative numbers to indicate error codes.
The value \c{-1} is \c{-ECOMPARTMENTFAIL} and other numbers from \file{errno.h} can be used to indicate other failures.

A CHERIoT capability is effectively a tagged union of a pointer and 64 bits of data.
You can take advantage of this in functions that return pointers to return either an integer or, if the result is not tagged, an error code.

To see a slightly less-contrived version of error handling, \ref{lst:safeuartyolo} is a version of \ref{lst:safeuartchecks}, rewritten to use error handling instead of checking.
The original version checked all of the properties of the string and protected itself against concurrent mutation.
This version still uses \cxx{check_pointer}, because this also prevents information disclosure by ensuring that the string does not overlap the current compartment invocation's stack.
You could omit this check if you are not worried about information disclosure.
For capabilities that you write through, this check is very important because otherwise you may write over parts of your own stack and corrupt internal state by accident.

The example then simply tries to read the bytes, assuming that they are a valid null-terminated C string.

\codelisting[marker=safe_uart,caption=Using structured error handling to ensure that a function does not crash.,label=lst:safeuartyolo, filename=examples/yolo_arguments/uart.cc]{}

This version uses the C++ wrappers that take lambdas, rather than the macro versions, but the semantics are the same as described earlier.
When you run this, you should see exactly the same output as the original version:

\begin{console}
No null
Non-malicious string
\end{console}

The string that lacks a null terminator will now simply be written looking for one.
The attempt to read one byte past the end will trigger a bounds exception.
This will then invoke the second lambda passed to \cxx{on_error}, which will set the error code and resume.
The other errors are caught by the \cxx{check_pointer} call.
If you remove that call, you will instead see the following output:

\begin{console}
No null


Non-malicious string
\end{console}

Now, each call is printing the trailing newline, even if it encountered a fault while reading the message.

\section[label=software_capabilities]{Building software capabilities with sealing}

The CHERI capability mechanism can be used to express arbitrary software-defined capabilities.
Recall that a capability, in the abstract, is an unforgeable token of authority that can be presented to allow some action.
In UNIX systems, for example, file descriptors are capabilities.
A userspace process cannot directly talk to the disk or the network, but if it presents a valid file descriptor to system calls such as \c{read} and \c{write} then the kernel will perform those operations on its behalf.

CHERIoT provides a mechanism to create arbitrary software-defined capabilities using the \keyword{sealing} mechanism (see \ref{sealing_intro}).
CHERIoT provides almost a few billion sealing types for use with software-defined capabilities.
You can allocate one of these dynamically by calling \c{token_key_new}.

\begin{caution}
There is no mechanism to reuse sealing capabilities.
As such, once you have allocated 4,278,190,079, you will be unable to create new ones.
A 20 MHz core doing nothing other than allocating new sealing capabilities could exhaust this space in around a day.
If untrusted code is allowed to allocate dynamic sealing capabilities then you may wish to restrict its access to this API and instead give it access to a wrapper that limits the number that it may allocate.
\end{caution}

\functiondoc{token_key_new}

You can also statically register a sealing type with the \c{STATIC_SEALING_TYPE()} macro.
This takes a single argument, the name that you wish to give the type.
This name is used both to refer to the static sealing capability is the name that will show up in auditing reports.

\macrodoc{STATIC_SEALING_TYPE}

You can access the sealing capability within the compartment that exported it using the \c{STATIC_SEALING_VALUE()} macro.
You can also refer to it in other compartments, but \textem{only} when constructing \keyword{static sealed objects}.
A static sealed object is like a global defined in a compartment, but that compartment can access it only via a sealed capability.

Static sealed objects are declared with \c{DECLARE_STATIC_SEALED_VALUE} and defined with \c{DEFINE_STATIC_SEALED_VALUE}.
These macros take both the name of the sealing type and the compartment that exposes it as arguments.
This ensures that there is no ambiguity and that accidental name collisions don't lead to security vulnerabilities.

\macrodoc{DECLARE_STATIC_SEALED_VALUE}

\hugo{
  I think this section would be helped by some example code listings.
}

Any object created in this way shows up in the audit log.
The exports section for the compartment that exposes the sealing key will will contain an entry like this:

\begin{jsonsnippet}
{
  "export_symbol": "__export.sealing_type.alloc.MallocKey",
  "exported": true,
  "kind": "SealingKey"
\},
\end{jsonsnippet}

\hugo{
  I would avoid going to in-depth with the auditing here.
  Just a brief explanation here without json snippets,
  and then have a link to a section in the Auditing chapter
  with a full description and json snippets.
}

This is cross-referenced with a section like this:

\begin{jsonsnippet}
{ 
  "contents": "00100000 00000000 00000000 00000000 00000000 00000000",
  "kind": "SealedObject",
  "sealing_type": {
    "compartment": "alloc",
    "key": "MallocKey",
    "provided_by": "build/cheriot/cheriot/release/cheriot.allocator.compartment",
    "symbol": "__export.sealing_type.alloc.MallocKey"
  \}
\},
\end{jsonsnippet}

This contains the full contents of the sealed object.
You can audit these in a firmware image to ensure that they are valid.

\begin{note}
Auditing a hex string is not easy.
A future version of CHERIoT RTOS will include tools to map these back to useful types.
See \ref{cheriot-audit} for more information about the CHERIoT Audit tool, which is designed for expressing policies over these properties.
\end{note}

This gives a building block that can be used to define arbitrary software-defined capabilities at system start.
A compartment that performs some action exposes a sealing type and a structure layout that it expects.
Static instances of this structure can be baked into the firmware image and then passed as sealed capabilities into the compartment that wishes to use them as capabilities.
They can be unsealed using the token APIs described in \ref{token_apis}.

The token APIs look as if they're provided by the allocator, but \c{token_obj_unseal} is a fast path implemented as a library.
This makes it fast to unseal objects (no cross-compartment call).
It also removes any dependency on the allocator from things that rely on static sealing.
\hugo{ A little more explanation here would be nice. Something like "The token API's methods normally require a cross compartment call, because ..." before introducing token_obj_unseal. }

The allocator provides an example in the RTOS of how you can use this feature.
When you allocate memory, you pass the allocator a static sealed object that represents your allocation capability, which authorises allocating memory up to a quota.
These contain a quota that is decreased on allocation and increased on deallocation.
A compartment can allocate memory only if it has an allocation capability and any allocation capability that it holds shows up in the audit report when linking a firmware image.

\section{Sharing globals between compartments}

CHERIoT supports a notion of pre-shared objects.
Each pre-shared object is allocated in a dedicated region of memory and can be imported into one or more compartments.
Each import can have a different set of permissions.

This model lets you define a global that is, for example, writeable by one compartment but readable from many, with no control flow between the communicating compartments.

Currently, the syntax for importing a pre-shared object is more verbose, a future version of the CHERIoT compiler will incorporate this into the type system and control imports via attributes on \c{extern} declarations.

You can import a pre-shared object with the \c{SHARED_OBJECT(type, name)} macro.
This takes the type of the object and its name (which must be globally unique across the firmware image) as arguments.
This evaluates to a pointer to the object.
Objects imported with this macro have the full set of permissions for imported objects.

You can also disable individual permissions using the \c{SHARED_OBJECT_WITH_PERMISSIONS} macros.
This takes an additional four additional boolean arguments that define the following set of permissions:

\begin{itemize}
	\item{Load}
	\item{Store}
	\item{Load or store capabilities}
	\item{Load mutable}
\end{itemize}

Note that load-mutable depends on both load and load/store capability permissions.
You cannot load a capability that has store permission if you cannot load a capability.

Shared objects are defined in the build system, by setting the \lua{shared_objects} value on a target (typically a compartment).
For example:

\begin{luasnippet}
    on_load(function(target)
        target:values_set("shared_objects", { exampleK = 1024, test_word = 4 \}, {expand = false\})
    end)
\end{luasnippet}

You don't need to define this on every compartment that imports the object, a single definition is all that is necessary.
This example is from the test suite and defines a \c{test_word} object that is a single 32-bit value and an \c{exampleK} object that is 1024 bytes.
Note that the objects are defined as sizes, not as types.
The type cannot be enforced by CHERI and depends on the compartment that imports the object.
If a single compartment has write access to an object then that compartment forms the TCB for type safety of that object.

